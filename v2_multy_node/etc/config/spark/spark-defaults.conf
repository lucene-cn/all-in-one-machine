#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
# spark.local.dir
# spark.files.userClassPathFirst

 spark.ui.port 10523
 spark.yarn.max.executor.failures 10000000
 spark.yarn.maxAppAttempts 10000000


 spark.scheduler.mode FAIR
 spark.hadoop.cloneConf true
 spark.serializer                 org.apache.spark.serializer.KryoSerializer
 

 spark.driver.maxResultSize 100m
 spark.eventLog.compress true
 spark.ui.retainedJobs 500
 spark.ui.retainedStages 500
 spark.worker.ui.retainedExecutors 100
 spark.worker.ui.retainedDrivers 100
 spark.sql.ui.retainedExecutions 100
 spark.streaming.ui.retainedBatches 100
 spark.sql.thriftserver.ui.retainedStatements 100
 

 #spark.history.provider org.apache.spark.deploy.yarn.history.YarnHistoryProvider 
 spark.history.ui.port 18080
 spark.yarn.containerLauncherMaxThreads 25
 #spark.yarn.services org.apache.spark.deploy.yarn.history.YarnHistoryService
 spark.yarn.preserve.staging.files false
 
 #memory manage
 spark.memory.useLegacyMode true
 spark.memory.offHeap.enabled false
 spark.memory.fraction 0.2
 spark.memory.storageFraction 0.5
 
 #memory deprecated
 spark.storage.memoryFraction 0.15
 spark.shuffle.memoryFraction 0.05
 spark.storage.unrollFraction 0.2
 #safety allow used in memoryFraction
 spark.storage.safetyFraction 0.9
 spark.shuffle.safetyFraction 0.8
 

 #spill manage
 spark.shuffle.spill true
 spark.shuffle.spill.numElementsForceSpillThreshold 50000
 #spark.reducer.maxReqsInFlight 10
 spark.reducer.maxSizeInFlight 4m
 spark.broadcast.blockSize 1m
 spark.broadcast.compress true
 

 spark.storage.memoryMapThreshold 512k
 spark.buffer.pageSize 1m
 spark.shuffle.io.preferDirectBufs false
 
 spark.sql.planner.sortMergeJoin=true
 spark.sql.autoBroadcastJoinThreshold -1
 
 
 
 spark.task.maxFailures 2
 spark.executor.heartbeatInterval 20s
 spark.akka.timeout 900s
 spark.akka.threads 24
 spark.network.timeout 1200s
 
 spark.files.useFetchCache false
 spark.files.fetchTimeout 300s
 spark.worker.timeout 300s
 spark.storage.blockManagerTimeoutIntervalMs 120s
 
 
 spark.scheduler.maxRegisteredResourcesWaitingTime 600s
 spark.scheduler.minRegisteredResourcesRatio 1
 #spark.scheduler.revive.interval 2s
 spark.speculation false
 
 spark.shuffle.io.retryWait 5s
 spark.shuffle.io.maxRetries 16
 spark.shuffle.sasl.timeout 30s
 spark.shuffle.io.serverThreads 24
 spark.shuffle.io.clientThreads 24
 spark.sql.shuffle.partitions 32
 
 spark.rpc.askTimeout 900s
 spark.rpc.lookupTimeout 900s
 spark.rpc.retry.wait 12s
 spark.rpc.numRetries 16
 spark.rpc.io.retryWait 5s
 spark.rpc.io.maxRetries 16
 spark.rpc.io.threads 24
 spark.rpc.io.serverThreads 24
 spark.rpc.io.clientThreads 24
 spark.rpc.sasl.timeout 30s
 
 #cleaner
 #spark.cleaner.referenceTracking true
 #spark.cleaner.referenceTracking.cleanCheckpoints true
 #spark.cleaner.referenceTracking.blocking false
 #spark.cleaner.referenceTracking.blocking.shuffle false
 
 spark.cleaner.periodicGC.interval 15min
 spark.io.compression.codec=lz4
 spark.shuffle.io.limitSize=false
 spark.shuffle.io.maxrwSize=5120000000
 spark.shuffle.io.agg.records=1024000000000
 spark.shuffle.io.sort.maxrwSize=5120000000
 spark.shuffle.io.collection.maxrwSize=5120000000

 


